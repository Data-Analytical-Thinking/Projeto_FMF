{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPEqRhv0+z4cLxh2w5kfxLe",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Data-Analytical-Thinking/Projeto_FMF/blob/Change%2FLogistic_Regression/Brach_apoio.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "atLlAgLyfcGG"
      },
      "outputs": [],
      "source": [
        "#Arquivo de testes! EM IMPLEMENTAÇÃO. \n",
        "#Engenharia reversa do codigo e substituição dos blocos\n",
        "\n",
        "\n",
        "best_score = 0\n",
        "\n",
        "for df.Logisticregression in range(1, 5): \n",
        "   \n",
        "    log_primal_Grid = GridSearchCV(LogisticRegression(solver='lbfgs'),param_grid, cv=10, refit=True, verbose=0)\n",
        "   \n",
        "    scores = cross_val_score(log_primal_Grid,:, df_train.columns != 'Exited'],df_train.Exited, scoring='accuracy')\n",
        "    \n",
        "    # compute mean cross-validation accuracy\n",
        "    score = np.mean(scores)\n",
        "    \n",
        "    # if we got a better score, store the score and parameters\n",
        "    if score > best_score:\n",
        "        best_score = score\n",
        "        best_parameter = md\n",
        "\n",
        "# Rebuild a model on the combined training and validation set        \n",
        "SelectedDTModel = GridSearchCV(LogisticRegression(solver='lbfgs'),param_grid, cv=10, refit=True, verbose=0).fit(df_train.columns != 'Exited'],df_train.Exited)\n",
        "\n",
        "test_score = SelectedDTModel.score(X_test_scaled, Y_test)\n",
        "PredictedOutput = SelectedDTModel.predict(X_test_scaled)\n",
        "test_recall = recall_score(Y_test, PredictedOutput, pos_label=1)\n",
        "fpr, tpr, thresholds = roc_curve(Y_test, PredictedOutput, pos_label=1)\n",
        "test_auc = auc(fpr, tpr)\n",
        "print(\"Best accuracy on validation set is:\", best_score)\n",
        "print(\"Best parameter for the maximum depth is: \", best_parameter)\n",
        "print(\"Test accuracy with best parameter is \", test_score)\n",
        "print(\"Test recall with best parameters is \", test_recall)\n",
        "print(\"Test AUC with the best parameter is \", test_auc)\n",
        "\n",
        "m = 'Decision Tree'\n",
        "acc.append([m, test_score, test_recall, test_auc, fpr, tpr, thresholds])"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "best_score=0\n",
        "kfolds=5 # set the number of folds\n",
        "\n",
        "for c in [0.001, 0.1, 1, 10, 100]:\n",
        "    logRegModel = LogisticRegression(C=c)\n",
        "    # perform cross-validation\n",
        "    scores = cross_val_score(logRegModel, X_trainval, Y_trainval, cv=kfolds, scoring='accuracy') # Get recall for each parameter setting\n",
        "    \n",
        "    # compute mean cross-validation accuracy\n",
        "    score = np.mean(scores)\n",
        "    \n",
        "    # Find the best parameters and score\n",
        "    if score > best_score:\n",
        "        best_score = score\n",
        "        best_parameters = c\n",
        "\n",
        "# rebuild a model on the combined training and validation set\n",
        "SelectedLogRegModel = LogisticRegression(C=best_parameters).fit(X_trainval_scaled, Y_trainval)\n",
        "\n",
        "test_score = SelectedLogRegModel.score(X_test_scaled, Y_test)\n",
        "PredictedOutput = SelectedLogRegModel.predict(X_test_scaled)\n",
        "test_recall = recall_score(Y_test, PredictedOutput, pos_label=1)\n",
        "fpr, tpr, thresholds = roc_curve(Y_test, PredictedOutput, pos_label=1)\n",
        "test_auc = auc(fpr, tpr)\n",
        "print(\"Best accuracy on validation set is:\", best_score)\n",
        "print(\"Best parameter for regularization (C) is: \", best_parameters)\n",
        "print(\"Test accuracy with best C parameter is\", test_score)\n",
        "print(\"Test recall with the best C parameter is\", test_recall)\n",
        "print(\"Test AUC with the best C parameter is\", test_auc)\n",
        "m = 'Logistic Regression (w/ imputation)'\n",
        "acc.append([m, test_score, test_recall, test_auc, fpr, tpr, thresholds])"
      ],
      "metadata": {
        "id": "0iMVnyRqgG6D"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}